{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "OmOhkDPbbyZQ",
        "outputId": "ff71d79a-b9a9-4865-952c-b3ef1bb53044"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7e7a8172-912f-4a13-9e35-b75f1da7352c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7e7a8172-912f-4a13-9e35-b75f1da7352c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving hdereport.csv to hdereport (1).csv\n",
            "        unhealthy  signal_strength  battery_voltage  temperature  \\\n",
            "0           False                4            3.549          NaN   \n",
            "1           False                4            3.559          NaN   \n",
            "2           False                4              NaN          NaN   \n",
            "3           False                4            3.557          NaN   \n",
            "4           False                4            3.549          NaN   \n",
            "...           ...              ...              ...          ...   \n",
            "749995      False                5            3.672         28.8   \n",
            "749996      False                5            3.672         26.9   \n",
            "749997      False                5            3.669         27.9   \n",
            "749998      False                5            3.672         25.3   \n",
            "749999      False                5            3.672         26.1   \n",
            "\n",
            "        days_offline  device_age_days  humidity_percentage  \n",
            "0                  1              814                  NaN  \n",
            "1                  1              814                  NaN  \n",
            "2                  1              814                  NaN  \n",
            "3                  1              814                  NaN  \n",
            "4                  1              814                  NaN  \n",
            "...              ...              ...                  ...  \n",
            "749995             0               59                 49.0  \n",
            "749996             0               59                 69.0  \n",
            "749997             0               59                 51.0  \n",
            "749998             0               59                 52.0  \n",
            "749999             0               59                 53.0  \n",
            "\n",
            "[750000 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "uploaded=files.upload()\n",
        "file_path= list(uploaded.keys())[0]\n",
        "data=pd.read_csv(file_path)\n",
        "df=pd.DataFrame(data)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#columns_to_drop=['facility', 'unit_name', 'device_id', 'vintage', 'inventory', 'last_contact', 'disposition', 'tansmit_count', 'event_occured_at(Date)' ]\n",
        "#df=df.drop(columns=columns_to_drop)\n",
        "df['unhealthy'] = df['unhealthy'].astype(bool)\n",
        "df['unhealthy'] = df['unhealthy'].map({False: 0, True: 1})\n",
        "df = df.dropna(subset=['temperature', 'humidity_percentage'])\n",
        "def impute_with_previous_mean(column):\n",
        "    rolling_mean = column.fillna(method='ffill').rolling(window=2, min_periods=1).mean()\n",
        "    rolling_mean = rolling_mean.fillna(method='bfill')\n",
        "    return rolling_mean\n",
        "df['temperature'] = impute_with_previous_mean(df['temperature'])\n",
        "df['humidity_percentage'] = impute_with_previous_mean(df['humidity_percentage'])\n",
        "df['signal_strength'] = impute_with_previous_mean(df['signal_strength'])\n",
        "df['battery_voltage'] = impute_with_previous_mean(df['battery_voltage'])\n",
        "df['days_offline'] = impute_with_previous_mean(df['days_offline'])\n",
        "df['device_age_days']= impute_with_previous_mean(df['device_age_days'])\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "IezvIfH_tSSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "726ec8a6-3921-4cda-f995-6cccf9e95568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        unhealthy  signal_strength  battery_voltage  temperature  \\\n",
            "189136          0              5.0           3.5440        16.20   \n",
            "189137          0              5.0           3.5490        16.85   \n",
            "189139          0              5.0           3.5565        17.80   \n",
            "189140          0              5.0           3.5650        19.15   \n",
            "189141          0              5.0           3.5700        20.50   \n",
            "...           ...              ...              ...          ...   \n",
            "749995          0              5.0           3.6705        27.50   \n",
            "749996          0              5.0           3.6720        27.85   \n",
            "749997          0              5.0           3.6705        27.40   \n",
            "749998          0              5.0           3.6705        26.60   \n",
            "749999          0              5.0           3.6720        25.70   \n",
            "\n",
            "        days_offline  device_age_days  humidity_percentage  \n",
            "189136           0.0           1015.0                 75.0  \n",
            "189137           0.0           1015.0                 66.5  \n",
            "189139           0.0           1015.0                 52.5  \n",
            "189140           0.0           1015.0                 50.5  \n",
            "189141           0.0           1015.0                 54.0  \n",
            "...              ...              ...                  ...  \n",
            "749995           0.0             59.0                 52.0  \n",
            "749996           0.0             59.0                 59.0  \n",
            "749997           0.0             59.0                 60.0  \n",
            "749998           0.0             59.0                 51.5  \n",
            "749999           0.0             59.0                 52.5  \n",
            "\n",
            "[459203 rows x 7 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-52a733ce6660>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['temperature'] = impute_with_previous_mean(df['temperature'])\n",
            "<ipython-input-3-52a733ce6660>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['humidity_percentage'] = impute_with_previous_mean(df['humidity_percentage'])\n",
            "<ipython-input-3-52a733ce6660>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['signal_strength'] = impute_with_previous_mean(df['signal_strength'])\n",
            "<ipython-input-3-52a733ce6660>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['battery_voltage'] = impute_with_previous_mean(df['battery_voltage'])\n",
            "<ipython-input-3-52a733ce6660>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['days_offline'] = impute_with_previous_mean(df['days_offline'])\n",
            "<ipython-input-3-52a733ce6660>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['device_age_days']= impute_with_previous_mean(df['device_age_days'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop('unhealthy', axis=1), df['unhealthy'], test_size=0.3, random_state=42)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_class = RandomForestClassifier(class_weight='balanced',random_state=42)\n",
        "rf_class.fit(X_train, y_train)\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from google.colab import files\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_class.predict(X_test)\n",
        "# Evaluate the model's performance\n",
        "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
        "print('Precision: {:.2f}'.format(precision_score(y_test, y_pred)))\n",
        "print('Recall: {:.2f}'.format(recall_score(y_test, y_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(y_test, y_pred)))\n",
        "#RANDOM FOREST IS DECIDED TO BE THE ALGORITHM THAT WILL BE CONSIDERED IN THE MODEL\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPuEqTCyvLpP",
        "outputId": "88201a66-99c5-4a09-8ba5-e677550e7652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.99\n",
            "Precision: 0.96\n",
            "Recall: 0.97\n",
            "F1 Score: 0.96\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    127852\n",
            "           1       0.96      0.97      0.96      9909\n",
            "\n",
            "    accuracy                           0.99    137761\n",
            "   macro avg       0.98      0.98      0.98    137761\n",
            "weighted avg       0.99      0.99      0.99    137761\n",
            "\n",
            "Confusion Matrix:\n",
            "[[127431    421]\n",
            " [   345   9564]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "model = open(\"\\D:\\Chathu Intern\\sd\\sdprediction.pkl\", \"wb\")\n",
        "pickle.dump(rf_class,model)\n",
        "model.close()"
      ],
      "metadata": {
        "id": "bU-7d-qYv7TL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"\\D:\\Chathu Intern\\sd\\sdprediction.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "BWOO7v9b0eHl",
        "outputId": "73340da9-a500-448d-a592-02d877543a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_949f0a70-c5c4-4378-8212-c689dbdc9861\", \"\\\\D:\\\\Chathu Intern\\\\sd\\\\sdprediction.pkl\", 27271599)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LeZnmCsBt_t-",
        "outputId": "9d2713e1-3203-4573-8ec8-e465f5d53ef8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4442cfd4-d4bf-4097-b782-d787b0aa1e6f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4442cfd4-d4bf-4097-b782-d787b0aa1e6f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Historical device events report_Untitled Page_Table.csv to Historical device events report_Untitled Page_Table (1).csv\n",
            "                                 facility unit_name device_id vintage  \\\n",
            "0                  Katy Ranch - TX-KAT-01      1225   bd00524      bd   \n",
            "1                  Katy Ranch - TX-KAT-01      1225   bd00524      bd   \n",
            "2                  Katy Ranch - TX-KAT-01      1225   bd00524      bd   \n",
            "3                  Katy Ranch - TX-KAT-01      1225   bd00524      bd   \n",
            "4                  Katy Ranch - TX-KAT-01      1225   bd00524      bd   \n",
            "...                                   ...       ...       ...     ...   \n",
            "749995  Bay Rock Self Storage - CA-MIL-01     D0038   BR00732      BR   \n",
            "749996  Bay Rock Self Storage - CA-MIL-01     D0038   BR00732      BR   \n",
            "749997  Bay Rock Self Storage - CA-MIL-01     D0038   BR00732      BR   \n",
            "749998  Bay Rock Self Storage - CA-MIL-01     D0038   BR00732      BR   \n",
            "749999  Bay Rock Self Storage - CA-MIL-01     D0038   BR00732      BR   \n",
            "\n",
            "       inventory              last_contact  unhealthy disposition  \\\n",
            "0             no  Jul 3, 2024, 11:15:26 PM      False  in_service   \n",
            "1             no  Jul 3, 2024, 11:15:26 PM      False  in_service   \n",
            "2             no  Jul 3, 2024, 11:15:26 PM      False  in_service   \n",
            "3             no  Jul 3, 2024, 11:15:26 PM      False  in_service   \n",
            "4             no  Jul 3, 2024, 11:15:26 PM      False  in_service   \n",
            "...          ...                       ...        ...         ...   \n",
            "749995        no   Jul 4, 2024, 1:13:21 AM      False  in_service   \n",
            "749996        no   Jul 4, 2024, 1:13:21 AM      False  in_service   \n",
            "749997        no   Jul 4, 2024, 1:13:21 AM      False  in_service   \n",
            "749998        no   Jul 4, 2024, 1:13:21 AM      False  in_service   \n",
            "749999        no   Jul 4, 2024, 1:13:21 AM      False  in_service   \n",
            "\n",
            "        signal_strength  battery_voltage  temperature  transmit_count  \\\n",
            "0                     4            3.539          NaN             NaN   \n",
            "1                     4            3.552          NaN             NaN   \n",
            "2                     4            3.544          NaN             NaN   \n",
            "3                     4            3.539          NaN             NaN   \n",
            "4                     4            3.547          NaN             NaN   \n",
            "...                 ...              ...          ...             ...   \n",
            "749995                4            3.502          NaN             NaN   \n",
            "749996                4            3.507          NaN             NaN   \n",
            "749997                4            3.536          NaN             NaN   \n",
            "749998                4            3.522          NaN             NaN   \n",
            "749999                4            3.495          NaN             NaN   \n",
            "\n",
            "        days_offline  device_age_days  humidity_percentage  temperature.1  \\\n",
            "0                  1              814                  NaN            NaN   \n",
            "1                  1              814                  NaN            NaN   \n",
            "2                  1              814                  NaN            NaN   \n",
            "3                  1              814                  NaN            NaN   \n",
            "4                  1              814                  NaN            NaN   \n",
            "...              ...              ...                  ...            ...   \n",
            "749995             0              367                  NaN            NaN   \n",
            "749996             0              367                  NaN            NaN   \n",
            "749997             0              367                  NaN            NaN   \n",
            "749998             0              367                  NaN            NaN   \n",
            "749999             0              367                  NaN            NaN   \n",
            "\n",
            "       event_occurred_at (Date)  \n",
            "0                  Jan 20, 2024  \n",
            "1                   Jan 6, 2024  \n",
            "2                  Jan 28, 2024  \n",
            "3                  Jan 22, 2024  \n",
            "4                  Jan 29, 2024  \n",
            "...                         ...  \n",
            "749995              Jan 6, 2024  \n",
            "749996             Jan 16, 2024  \n",
            "749997             Jan 18, 2024  \n",
            "749998             Jan 23, 2024  \n",
            "749999              Jan 6, 2024  \n",
            "\n",
            "[750000 rows x 17 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from google.colab import files\n",
        "uploaded=files.upload()\n",
        "file_path= list(uploaded.keys())[0]\n",
        "d=pd.read_csv(file_path)\n",
        "print(d)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gK68KOrn22dp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fb802a4-02c5-4cb3-fc8b-894cab1c7dfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        signal_strength  battery_voltage  temperature  days_offline  \\\n",
            "27048                 5            3.511          7.7             0   \n",
            "27049                 5            3.519          7.8             0   \n",
            "27050                 5            3.551         16.3             0   \n",
            "27051                 5            3.546         16.6             0   \n",
            "27052                 5            3.541         14.2             0   \n",
            "...                 ...              ...          ...           ...   \n",
            "345284                5            3.528         18.6             0   \n",
            "345285                5            3.528         18.0             0   \n",
            "345287                5            3.526         18.1             0   \n",
            "345288                5            3.526         17.9             0   \n",
            "345289                5            3.526         17.3             0   \n",
            "\n",
            "        device_age_days  humidity_percentage  \n",
            "27048              1015                 44.0  \n",
            "27049              1015                 56.0  \n",
            "27050              1015                 65.0  \n",
            "27051              1015                 80.0  \n",
            "27052              1015                 50.0  \n",
            "...                 ...                  ...  \n",
            "345284              205                 59.0  \n",
            "345285              205                 49.0  \n",
            "345287              205                 42.0  \n",
            "345288              205                 50.0  \n",
            "345289              205                 47.0  \n",
            "\n",
            "[278763 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "d = d.dropna(subset=['temperature', 'humidity_percentage'])\n",
        "d.columns=['facility','unit_name','device_id','vintage','inventory','last_contact','unhealthy','disposition','signal_strength','battery_voltage','temperature','transmit_count','days_offline','device_age_days','humidity_percentage','temperature.1','event_occurred_at (Date)']\n",
        "X_test=d[['signal_strength','battery_voltage','temperature','days_offline','device_age_days','humidity_percentage',]]\n",
        "X_test=X_test[['signal_strength','battery_voltage','temperature','days_offline','device_age_days','humidity_percentage']]\n",
        "print(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = 'sdprediction.pkl'\n",
        "loaded_model = pickle.load(open(filename,'rb'))\n",
        "result = loaded_model.predict(rf_class,X_test)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zBauy6lU1jd-",
        "outputId": "aa623df1-c88b-4472-91fd-ad49e575b8bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in result:\n",
        "  if(i==1):\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEIf4Nsp2lfy",
        "outputId": "a81e74f4-f5c7-4c49-9cd8-a431267c8e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "rows_with_true = result[(result == 1)]\n",
        "if not rows_with_true.any:\n",
        "    print(\"Rows containing the value True:\")\n",
        "    print(rows_with_true)\n",
        "else:\n",
        "    print(\"No rows contain the value True.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xF11ExJBWi3g",
        "outputId": "fcf841fb-f0bf-4e09-d0ac-d048e28f8169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No rows contain the value True.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}